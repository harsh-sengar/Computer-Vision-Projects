{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_detection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EPj-qNuo19YiAYN0b0vg1QiVjrHOV7v2",
      "authorship_tag": "ABX9TyNYKJ8SX+mEKyIce3yEyk1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-sengar/Computer-Vision-Projects/blob/main/Object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXjK7rayEUqY"
      },
      "source": [
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "# !wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBJumKIbyATX"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "860h1FpQGEDZ"
      },
      "source": [
        "cd /content/gdrive/MyDrive/Research/Object Detection/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNQvhZgrNTk3"
      },
      "source": [
        "# !mkdir test\n",
        "# !mv ./VOCtest_06-Nov-2007.tar ./test/\n",
        "# !tar -xf ./test/VOCtest_06-Nov-2007.tar\n",
        "# !mv ./VOCdevkit/ ./test/\n",
        "# !tar -xf VOCtrainval_06-Nov-2007.tar\n",
        "# #!rm -r VOCdevkit/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7BVy4fqEXpI"
      },
      "source": [
        "import xml.etree.ElementTree as et\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import copy\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jlm2dGH-3NX"
      },
      "source": [
        "class object_detection(Dataset):\n",
        "  def __init__(self,label_dict,train_files,data_transforms=None):\n",
        "    self.data = [] # Bounding box coordinate\n",
        "    self.labels = [] # Label of the object in that bounding box\n",
        "    self.paths = [] # Path of the image\n",
        "    self.data_bbox = {} # Coordinates of all the bounding box  \n",
        "\n",
        "    for i in train_files:\n",
        "      tree = et.parse(i)\n",
        "      path = './VOCdevkit/VOC2007/JPEGImages/'+i[i.rfind('/')+1:].split('.')[0]+'.jpg'\n",
        "      img = cv2.imread(path)\n",
        "\n",
        "      bndbox = []\n",
        "\n",
        "      root = tree.getroot()\n",
        "      for child in root:\n",
        "        if child.tag=='object':\n",
        "          name = ''\n",
        "          for child1 in child:\n",
        "            \n",
        "            if child1.tag=='name':\n",
        "              name = child1.text\n",
        "            elif child1.tag=='bndbox':\n",
        "              #print(name)\n",
        "              #print(child1[0].text,child1[1].text,child1[2].text,child1[3].text)\n",
        "              x_min = int(child1[0].text)\n",
        "              y_min = int(child1[1].text)\n",
        "              x_max = int(child1[2].text)\n",
        "              y_max = int(child1[3].text)\n",
        "              #cv2.rectangle(img,(x_min,y_min),(x_max,y_max),(255,0,0),2)\n",
        "              \n",
        "              bndbox.append([x_min,y_min,x_max,y_max])\n",
        "              self.data.append([x_min,y_min,x_max,y_max])\n",
        "              self.labels.append(label_dict[name])\n",
        "              self.paths.append(path)\n",
        "              #cv2_imshow(img)\n",
        "\n",
        "      self.data_bbox[path] = bndbox\n",
        "\n",
        "    # Generate random patch to create a new background class\n",
        "    j=0\n",
        "    count=393\n",
        "    while j<count:\n",
        "      images = list(self.data_bbox.keys())\n",
        "      choice = np.random.randint(0,len(images))\n",
        "      bndbox = self.data_bbox[images[choice]]\n",
        "      \n",
        "      img = cv2.imread(images[choice])\n",
        "    \n",
        "      h,w,ch = img.shape\n",
        "      #print(bndbox)\n",
        "      #print(h,w,ch)\n",
        "      #print('\\n\\n')\n",
        "\n",
        "      \n",
        "      #for i in bndbox:\n",
        "        #cv2.rectangle(img,(i[0],i[1]),(i[2],i[3]),(255,0,0),2)\n",
        "      \n",
        "      #cv2_imshow(img)\n",
        "      \n",
        "      #check = (False,1.5)\n",
        "      for times in range(6):\n",
        "        step_size1 = np.round((0.5)*np.random.random_sample()+0.3,1)\n",
        "        step_size2 = np.round((0.5)*np.random.random_sample()+0.3,1)\n",
        "        delta_h = int(h*step_size1)\n",
        "        delta_w = int(w*step_size2)\n",
        "\n",
        "        #print(len(images),choice)\n",
        "        y_min = np.random.randint(0,150)\n",
        "        if y_min+delta_h>h:\n",
        "          y_max = h\n",
        "        else:\n",
        "          y_max = y_min+delta_h\n",
        "        \n",
        "        x_min = np.random.randint(0,150)\n",
        "        if x_min+delta_w>w:\n",
        "          x_max = w\n",
        "        else:\n",
        "          x_max = x_min+delta_w\n",
        "        check = self.intersection_union(b=[x_min,y_min,x_max,y_max],bndbox=bndbox)\n",
        "        if check[0]:\n",
        "          #print([x_min,y_min,x_max,y_max])\n",
        "          #print(check[1])\n",
        "          break\n",
        "      \n",
        "      if check[0]:\n",
        "        #img1 = img[y_min:y_max,x_min:x_max]\n",
        "        #cv2_imshow(img1)\n",
        "        self.data.append([x_min,y_min,x_max,y_max])\n",
        "        self.labels.append(0)\n",
        "        self.paths.append(images[choice])\n",
        "        j+=1\n",
        "    \n",
        "    self.n_samples = len(self.data)\n",
        "\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    \n",
        "    img = Image.open(self.paths[index])\n",
        "    x_min = self.data[index][0]\n",
        "    y_min = self.data[index][1]\n",
        "    x_max = self.data[index][2]\n",
        "    y_max = self.data[index][3]\n",
        "    img1 =  img.crop((x_min,y_min,x_max,y_max))#img[y_min:y_max,x_min:x_max]\n",
        "\n",
        "    \n",
        "    #img1 = Image.open('temp.png')\n",
        "\n",
        "    if data_transforms:\n",
        "      img1 = data_transforms(img1)\n",
        "\n",
        "    return img1,self.labels[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "  \n",
        "  def intersection_union(self,b,bndbox):\n",
        "    max_val=0\n",
        "    for b1 in bndbox:\n",
        "      x1_min = b[0]\n",
        "      y1_min = b[1]\n",
        "      x1_max = b[2]\n",
        "      y1_max = b[3]\n",
        "      \n",
        "      x2_min = b1[0]\n",
        "      y2_min = b1[1]\n",
        "      x2_max = b1[2]\n",
        "      y2_max = b1[3]\n",
        "\n",
        "      #print(x1_min,y1_min,x1_max,y1_max,x2_min,y2_min,x2_max,y2_max)\n",
        "\n",
        "      x_dist = max(0,(min(x1_max,x2_max) - max(x1_min,x2_min)))\n",
        "      y_dist = max(0,(min(y1_max,y2_max)-max(y1_min,y2_min)))\n",
        "\n",
        "      intersect = x_dist * y_dist\n",
        "      \n",
        "      union = (x1_max-x1_min)*(y1_max-y1_min)+(x2_max-x2_min)*(y2_max-y2_min)-intersect\n",
        "\n",
        "      max_val = max(max_val,intersect/union)\n",
        "      \n",
        "      if (intersect/union)>0.2:\n",
        "        #print(b1)\n",
        "        #print(intersect/union)\n",
        "        return False,1.5\n",
        "    \n",
        "    return True,max_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkgPNDEQDppU"
      },
      "source": [
        "class object_detection_test(Dataset):\n",
        "  def __init__(self,label_dict,data_transforms=None):\n",
        "    self.data = []\n",
        "    self.labels = []\n",
        "    self.paths = []\n",
        "    self.data1 = {} \n",
        "\n",
        "    files = []\n",
        "\n",
        "    for xyz in os.walk('./test/VOCdevkit/VOC2007/Annotations/'):\n",
        "      path = xyz[0]\n",
        "      for val in xyz[2]:\n",
        "        files.append(path+val)\n",
        "\n",
        "\n",
        "    for i in files:\n",
        "      tree = et.parse(i)\n",
        "      path = './test/VOCdevkit/VOC2007/JPEGImages/'+i[i.rfind('/')+1:].split('.')[0]+'.jpg'\n",
        "      \n",
        "      #print(type(img))\n",
        "      #print(img.shape)\n",
        "      bndbox = []\n",
        "\n",
        "      root = tree.getroot()\n",
        "      for child in root:\n",
        "        if child.tag=='object':\n",
        "          name = ''\n",
        "          for child1 in child:\n",
        "            \n",
        "            if child1.tag=='name':\n",
        "              name = child1.text\n",
        "            elif child1.tag=='bndbox':\n",
        "              #print(name)\n",
        "              #classes.add(name)\n",
        "              #print(child1[0].text,child1[1].text,child1[2].text,child1[3].text)\n",
        "              x_min = int(child1[0].text)\n",
        "              y_min = int(child1[1].text)\n",
        "              x_max = int(child1[2].text)\n",
        "              y_max = int(child1[3].text)\n",
        "              #cv2.rectangle(img,(x_min,y_min),(x_max,y_max),(255,0,0),2)\n",
        "              \n",
        "              bndbox.append([x_min,y_min,x_max,y_max])\n",
        "              self.data.append([x_min,y_min,x_max,y_max])\n",
        "              self.labels.append(label_dict[name])\n",
        "              self.paths.append(path)\n",
        "              #cv2_imshow(img1)\n",
        "\n",
        "      self.data1[path] = bndbox\n",
        "\n",
        "    j=0\n",
        "    count=391\n",
        "    while j<count:\n",
        "      images = list(self.data1.keys())\n",
        "      choice = np.random.randint(0,len(images))\n",
        "      bndbox = self.data1[images[choice]]\n",
        "      \n",
        "      img = cv2.imread(images[choice])\n",
        "    \n",
        "      h,w,ch = img.shape\n",
        "      #print(bndbox)\n",
        "      #print(h,w,ch)\n",
        "      #print('\\n\\n')\n",
        "\n",
        "      \n",
        "      #for i in bndbox:\n",
        "        #cv2.rectangle(img,(i[0],i[1]),(i[2],i[3]),(255,0,0),2)\n",
        "      \n",
        "      #cv2_imshow(img)\n",
        "      \n",
        "      #check = (False,1.5)\n",
        "      for times in range(6):\n",
        "        step_size1 = np.round((0.5)*np.random.random_sample()+0.3,1)\n",
        "        step_size2 = np.round((0.5)*np.random.random_sample()+0.3,1)\n",
        "        delta_h = int(h*step_size1)\n",
        "        delta_w = int(w*step_size2)\n",
        "\n",
        "        #print(len(images),choice)\n",
        "        y_min = np.random.randint(0,150)\n",
        "        if y_min+delta_h>h:\n",
        "          y_max = h\n",
        "        else:\n",
        "          y_max = y_min+delta_h\n",
        "        \n",
        "        x_min = np.random.randint(0,150)\n",
        "        if x_min+delta_w>w:\n",
        "          x_max = w\n",
        "        else:\n",
        "          x_max = x_min+delta_w\n",
        "        check = self.intersection_union(b=[x_min,y_min,x_max,y_max],bndbox=bndbox)\n",
        "        if check[0]:\n",
        "          #print([x_min,y_min,x_max,y_max])\n",
        "          #print(check[1])\n",
        "          break\n",
        "      \n",
        "      if check[0]:\n",
        "        #img1 = img[y_min:y_max,x_min:x_max]\n",
        "        #cv2_imshow(img1)\n",
        "        self.data.append([x_min,y_min,x_max,y_max])\n",
        "        self.labels.append(0)\n",
        "        self.paths.append(images[choice])\n",
        "        j+=1\n",
        "    \n",
        "    self.n_samples = len(self.data)\n",
        "\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    \n",
        "    img = Image.open(self.paths[index])\n",
        "    x_min = self.data[index][0]\n",
        "    y_min = self.data[index][1]\n",
        "    x_max = self.data[index][2]\n",
        "    y_max = self.data[index][3]\n",
        "    img1 =  img.crop((x_min,y_min,x_max,y_max))#img[y_min:y_max,x_min:x_max]\n",
        "\n",
        "    \n",
        "    #img1 = Image.open('temp.png')\n",
        "\n",
        "    if data_transforms:\n",
        "      img1 = data_transforms(img1)\n",
        "\n",
        "    return img1,self.labels[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "  \n",
        "  def intersection_union(self,b,bndbox):\n",
        "    max_val=0\n",
        "    for b1 in bndbox:\n",
        "      x1_min = b[0]\n",
        "      y1_min = b[1]\n",
        "      x1_max = b[2]\n",
        "      y1_max = b[3]\n",
        "      \n",
        "      x2_min = b1[0]\n",
        "      y2_min = b1[1]\n",
        "      x2_max = b1[2]\n",
        "      y2_max = b1[3]\n",
        "\n",
        "      #print(x1_min,y1_min,x1_max,y1_max,x2_min,y2_min,x2_max,y2_max)\n",
        "\n",
        "      x_dist = max(0,(min(x1_max,x2_max) - max(x1_min,x2_min)))\n",
        "      y_dist = max(0,(min(y1_max,y2_max)-max(y1_min,y2_min)))\n",
        "\n",
        "      intersect = x_dist * y_dist\n",
        "      \n",
        "      union = (x1_max-x1_min)*(y1_max-y1_min)+(x2_max-x2_min)*(y2_max-y2_min)-intersect\n",
        "\n",
        "      max_val = max(max_val,intersect/union)\n",
        "      \n",
        "      if (intersect/union)>0.2:\n",
        "        #print(b1)\n",
        "        #print(intersect/union)\n",
        "        return False,1.5\n",
        "    \n",
        "    return True,max_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yyvEVso70vM"
      },
      "source": [
        "f = open('./VOCdevkit/VOC2007/ImageSets/Main/train.txt')\n",
        "train_files = []\n",
        "for i in f.readlines():\n",
        "  i = i.split('\\n')[0]\n",
        "  train_files.append('./VOCdevkit/VOC2007/Annotations/'+i+'.xml')\n",
        "\n",
        "f1 = open('./VOCdevkit/VOC2007/ImageSets/Main/val.txt')\n",
        "val_files = []\n",
        "for i in f1.readlines():\n",
        "  i = i.split('\\n')[0]\n",
        "  val_files.append('./VOCdevkit/VOC2007/Annotations/'+i+'.xml')\n",
        "\n",
        "\n",
        "print(train_files)\n",
        "print(val_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG6M_zCFW73H"
      },
      "source": [
        "train_files_temp = [train_files[0]]\n",
        "val_files_temp = [val_files[0]]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzm1dyiLXNe8"
      },
      "source": [
        "val_files_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Zz-ohJn-_A"
      },
      "source": [
        "data_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                          std = [0.229, 0.224, 0.225])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDSqwobg-Y8a"
      },
      "source": [
        "labels = {\n",
        " 'aeroplane': 18,\n",
        " 'background':0,\n",
        " 'bicycle': 1,\n",
        " 'bird': 15,\n",
        " 'boat': 6,\n",
        " 'bottle': 16,\n",
        " 'bus': 14,\n",
        " 'car': 12,\n",
        " 'cat': 11,\n",
        " 'chair': 13,\n",
        " 'cow': 19,\n",
        " 'diningtable': 20,\n",
        " 'dog': 5,\n",
        " 'horse': 2,\n",
        " 'motorbike': 10,\n",
        " 'person': 4,\n",
        " 'pottedplant': 7,\n",
        " 'sheep': 8,\n",
        " 'sofa': 9,\n",
        " 'train': 3,\n",
        " 'tvmonitor': 17}\n",
        "dataset_train = object_detection(label_dict=labels,train_files = train_files_temp,data_transforms=data_transforms)\n",
        "dataset_val = object_detection(label_dict=labels,train_files = val_files_temp,data_transforms = data_transforms)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkVdVGHQUHTW"
      },
      "source": [
        "dataset_test = object_detection_test(label_dict=labels,data_transforms=data_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wips0rt8-ZFx"
      },
      "source": [
        "first_data = dataset_train[0]\n",
        "print(first_data[0].shape)\n",
        "print(first_data[1])\n",
        "temp = first_data[0].numpy()\n",
        "inp = temp.transpose((1, 2, 0))\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "inp = std * inp + mean\n",
        "inp = np.clip(inp, 0, 1)\n",
        "plt.imshow(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8porlrrtWp_0"
      },
      "source": [
        "first_data = dataset_val[1]\n",
        "print(first_data[0].shape)\n",
        "print(first_data[1])\n",
        "temp = first_data[0].numpy()\n",
        "inp = temp.transpose((1, 2, 0))\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "inp = std * inp + mean\n",
        "inp = np.clip(inp, 0, 1)\n",
        "plt.imshow(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C71O8MIRWqOv"
      },
      "source": [
        "batch_size=32\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size, \n",
        "                                           shuffle=True,num_workers=8)\n",
        "validation_loader = DataLoader(dataset_val, batch_size=batch_size,\n",
        "                                                shuffle=True,num_workers=8)\n",
        "\n",
        "test_loader = DataLoader(dataset_test,batch_size=batch_size,num_workers=8)\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = train_loader\n",
        "dataloaders['val'] = validation_loader\n",
        "dataloaders['test'] = test_loader\n",
        "dataset_sizes = {'train':len(dataset_train),'val':len(dataset_val),'test':len(dataset_test)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fwf7tO2WqSH"
      },
      "source": [
        "print(dataset_sizes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vlW4uuZrJBC"
      },
      "source": [
        "#validation_split = 0.1\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "batch_size=16\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "'''dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "'''\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size, \n",
        "                                           shuffle=True,num_workers=8)\n",
        "validation_loader = DataLoader(dataset_val, batch_size=batch_size,\n",
        "                                                shuffle=True,num_workers=8)\n",
        "\n",
        "test_loader = DataLoader(dataset_test ,batch_size=batch_size,num_workers=8)\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = train_loader\n",
        "dataloaders['val'] = validation_loader\n",
        "dataloaders['test'] = test_loader\n",
        "dataset_sizes = {'train':len(dataset),'val':len(dataset1),'test':len(dataset2)}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m1VTn8e667E"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dataset_sizes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9xrRS1d67C7"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler,train_loss,val_loss,\n",
        "                train_acc,val_acc,num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train','train1', 'val']:\n",
        "            eval = False\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            elif phase=='train1':\n",
        "                eval = True\n",
        "                model.eval()\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            if eval:\n",
        "              phase = 'train'\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                if eval:\n",
        "                  phase = 'train1'\n",
        "\n",
        "                '''print('inputs')\n",
        "                print(inputs.shape)\n",
        "                print('labels')\n",
        "                print(labels)'''\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    prob = nn.functional.softmax(outputs)\n",
        "                    '''print('outputs')\n",
        "                    print(outputs)\n",
        "                    print('prob')\n",
        "                    print(prob)'''\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    #print('_')\n",
        "                    #print(_)\n",
        "                    #print('preds')\n",
        "                    #print(preds)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    #print('labels')\n",
        "                    #print(labels)\n",
        "                    #print('loss')\n",
        "                    #print(loss)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                \n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            if eval:\n",
        "              phase = 'train'\n",
        "            \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            if eval:\n",
        "              phase = 'train1'\n",
        "\n",
        "            if phase!='train':\n",
        "              print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            if phase == 'train1':\n",
        "              train_loss.append(epoch_loss)\n",
        "              train_acc.append(epoch_acc)\n",
        "            elif phase=='val':\n",
        "              val_loss.append(epoch_loss)\n",
        "              val_acc.append(epoch_acc)\n",
        "            \n",
        "            time_elapsed = time.time() - since\n",
        "            print('Epoch complete in {:.0f}m {:.0f}s'.format(\n",
        "              time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dC6V0F_67JQ"
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 21)\n",
        "\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=50, gamma=0.1)\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "train_acc = []\n",
        "val_acc = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avkYS9Ho67M8"
      },
      "source": [
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0001, momentum=0.9)\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       train_loss,val_loss,train_acc,val_acc,num_epochs=30)\n",
        "print(train_loss)\n",
        "print(val_loss)\n",
        "print(train_acc)\n",
        "print(val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp73YfiG67Qf"
      },
      "source": [
        "plt.plot(range(80),train_loss,color='blue',label='training')\n",
        "plt.plot(range(80),val_loss,color='green',label = 'validation')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.title('lr=0.01, momentum=0.9) lr_scheduler.StepLR(optimizer_ft, step_size=50, gamma=0.05)')\n",
        "plt.savefig('loss_epoch_curve.png')\n",
        "plt.show()\n",
        "\n",
        "train_acc1 = [float(i) for i in train_acc]\n",
        "val_acc1 = [float(i) for i in val_acc]\n",
        "\n",
        "plt.plot(range(80),train_acc1,color='blue',label='training')\n",
        "plt.plot(range(80),val_acc1,color='green',label = 'validation')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.title('lr=0.01, momentum=0.9) lr_scheduler.StepLR(optimizer_ft, step_size=50, gamma=0.05)')\n",
        "plt.savefig(\"accuracy_epoch_curve.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEGh6ip367U1"
      },
      "source": [
        "phase = 'test'\n",
        "running_loss = 0.0\n",
        "since = time.time()\n",
        "running_corrects = 0\n",
        "for inputs, labels in dataloaders['test']:\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "  with torch.set_grad_enabled(phase == 'train'):\n",
        "    outputs = model_ft(inputs)\n",
        "    prob = nn.functional.softmax(outputs)\n",
        "                    \n",
        "    _, preds = torch.max(outputs, 1)\n",
        "                    \n",
        "    loss = criterion(outputs, labels)\n",
        "                    \n",
        "    if phase == 'train':\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "  running_loss += loss.item() * inputs.size(0)\n",
        "                \n",
        "  running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "\n",
        "epoch_loss = running_loss / dataset_sizes[phase]\n",
        "epoch_acc = running_corrects.double() / dataset_sizes['test']\n",
        "\n",
        "print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "time_elapsed = time.time() - since\n",
        "print('Epoch complete in {:.0f}m {:.0f}s'.format(\n",
        "\n",
        "time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnmgl02S75aU"
      },
      "source": [
        "torch.save(model_ft,\"model\")\n",
        "if torch.cuda.is_available():\n",
        "  model_ft = torch.load(\"./drive/MyDrive/object_detection/model\")\n",
        "else:\n",
        "  model_ft = torch.load(\"./drive/MyDrive/object_detection/model\",map_location='cpu')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKG_Xaj375dY"
      },
      "source": [
        "labels_dict = {\n",
        " 'aeroplane': 18,\n",
        " 'background':0,\n",
        " 'bicycle': 1,\n",
        " 'bird': 15,\n",
        " 'boat': 6,\n",
        " 'bottle': 16,\n",
        " 'bus': 14,\n",
        " 'car': 12,\n",
        " 'cat': 11,\n",
        " 'chair': 13,\n",
        " 'cow': 19,\n",
        " 'diningtable': 20,\n",
        " 'dog': 5,\n",
        " 'horse': 2,\n",
        " 'motorbike': 10,\n",
        " 'person': 4,\n",
        " 'pottedplant': 7,\n",
        " 'sheep': 8,\n",
        " 'sofa': 9,\n",
        " 'train': 3,\n",
        " 'tvmonitor': 17}\n",
        "class_names = {}\n",
        "for i in labels_dict:\n",
        "  class_names[labels_dict[i]] = i\n",
        "\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXAmrSTy75hP"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lghRbIKw75ld"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            prob = nn.functional.softmax(outputs)\n",
        "\n",
        "            print(prob.shape)\n",
        "          \n",
        "            prob,indices = torch.sort(prob,descending=True)\n",
        "            prob = prob[:,:3]\n",
        "            print(prob)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            print(inputs.size())\n",
        "            preds = preds.to(\"cpu\").numpy()\n",
        "            labels = labels.to(\"cpu\").numpy()\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                \n",
        "                \n",
        "                ax.set_title('predicted: {} {} {}'.format(class_names[preds[j]],prob[j],\n",
        "                                                        class_names[labels[j]]))\n",
        "                \n",
        "                imshow(inputs[j].to(\"cpu\"))\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TamjpAv75o2"
      },
      "source": [
        "visualize_model(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi9BOEqD8DdW"
      },
      "source": [
        "data_transforms = torchvision.transforms.Compose([torchvision.transforms.Resize((224,224))\n",
        "                    ,transforms.ToTensor()]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "havkwgEq8Dkk"
      },
      "source": [
        "list(dataset1.data1.keys())[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSV7wCkN8DpI"
      },
      "source": [
        "dataset1.data1['./VOCdevkit/VOC2007/JPEGImages/000009.jpg']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3i5Klv875t4"
      },
      "source": [
        "from PIL import ImageDraw\n",
        "\n",
        "img = Image.open('./VOCdevkit/VOC2007/JPEGImages/000005.jpg')\n",
        "\n",
        "w,h = img.size\n",
        "print(w,h)\n",
        "width  = [128,256,512,int(w/2),w]\n",
        "height = [128,256,512,int(h/2),h]\n",
        "\n",
        "boxes = []\n",
        "out = display(img,display_id=True)\n",
        "for s_w in width:\n",
        "  for s_h in height:\n",
        "    for y in range(0,h-s_h+1,16):\n",
        "      for x in range(0,w-s_w+1,16):\n",
        "        #img2 = copy.deepcopy(img)\n",
        "        #img1 = img.crop((x,y,x+s_w,y+s_h))\n",
        "        #img1 = data_transforms(img1)\n",
        "        #detections.append(img1)\n",
        "        boxes.append(torch.tensor([x,y,x+s_w,y+s_h]))\n",
        "        #im = ImageDraw.Draw(img2)\n",
        "        #im.rectangle([(x,y),(x+s_w,y+s_h)],outline='red')\n",
        "        #out.update(img2)\n",
        "        #time.sleep(0.1)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D6GRcO167Y2"
      },
      "source": [
        "len(boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdcCbNNM8PIC"
      },
      "source": [
        "#check_detections = torch.stack(detections)\n",
        "check_boxes = torch.stack(boxes)\n",
        "\n",
        "filter_detections = []\n",
        "filter_boxes = []\n",
        "filter_labels = []\n",
        "filter_scores = []\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "dataset = TensorDataset(check_boxes)\n",
        "temp1 = DataLoader(dataset,batch_size=32)\n",
        "\n",
        "\n",
        "model_ft.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  \n",
        "  for boxes1 in temp1:\n",
        "    detections = []\n",
        "    for i in boxes1[0]:\n",
        "      a = i[0].item()\n",
        "      b = i[1].item()\n",
        "      c = i[2].item()\n",
        "      d = i[3].item()\n",
        "\n",
        "      img1 = img.crop((a,b,c,d))\n",
        "      img1 = data_transforms(img1)\n",
        "      detections.append(img1)\n",
        "    \n",
        "    inputs = torch.stack(detections)\n",
        "    inputs = inputs.to(device)\n",
        "    \n",
        "\n",
        "    outputs = model_ft(inputs)\n",
        "    prob = nn.functional.softmax(outputs,dim=1)\n",
        "    \n",
        "\n",
        "  \n",
        "    prob,indices = torch.sort(prob,descending=True)\n",
        "    prob = prob[:,:1]\n",
        "    #print('prob',prob)\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    #print('_,preds ',_,preds)\n",
        "    #print('boxes1',boxes1)\n",
        "    \n",
        "    preds1 = preds.to(\"cpu\").numpy()\n",
        "    prob1 = prob.to(\"cpu\").numpy()\n",
        "\n",
        "    for i in range(len(preds1)):\n",
        "      \n",
        "      val = float(prob1[i])\n",
        "      #print('val',val)\n",
        "      if val>0.80:\n",
        "        \n",
        "        label = class_names[preds1[i]]\n",
        "        #print('label',label)\n",
        "        if label !='background':\n",
        "          #filter_detections.append(inputs[i])\n",
        "          \n",
        "          filter_boxes.append(boxes1[0][i])\n",
        "          filter_labels.append(label)\n",
        "          filter_scores.append(val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24IAVOxi8Pwz"
      },
      "source": [
        "temp = [list(i.numpy()) for i in filter_boxes]\n",
        "len(temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff_eEe4I8Up-"
      },
      "source": [
        "#run = np.array([[4,3,6,6],[4,1,6,3],[2,1,4,3],[2,3,4,6]])\n",
        "#print(run)\n",
        "#run = np.delete(run,[1,2],axis=0)\n",
        "#print(run)\n",
        "\n",
        "print(overlap[:10])\n",
        "print(len(idxs))\n",
        "#print(len(boxes_list))\n",
        "abc = [i[2] for i in temp1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP3TAw8B8UtY"
      },
      "source": [
        "def intersection_union(b,b1,idxs):\n",
        "  max_val=0\n",
        "  x1_min = b[0]\n",
        "  y1_min = b[1]\n",
        "  x1_max = b[2]\n",
        "  y1_max = b[3]\n",
        "  \n",
        "  x2_min = b1[idxs[:],0]\n",
        "  y2_min = b1[idxs[:],1]\n",
        "  x2_max = b1[idxs[:],2]\n",
        "  y2_max = b1[idxs[:],3]\n",
        "\n",
        "  #print(x1_min,y1_min,x1_max,y1_max,x2_min,y2_min,x2_max,y2_max)\n",
        "  \n",
        "\n",
        "  x1 = np.minimum(x1_max,x2_max)\n",
        "  x2 = np.maximum(x1_min,x2_min)\n",
        "  y1 = np.minimum(y1_max,y2_max)\n",
        "  y2 = np.maximum(y1_min,y2_min)\n",
        "\n",
        "  #print(x1,x2,y1,y2)\n",
        "\n",
        "  x_dist = np.maximum(0,(x1 - x2))\n",
        "  y_dist = np.maximum(0,(y1-y2))\n",
        "\n",
        "  intersect = x_dist * y_dist\n",
        "  \n",
        "  union = (x1_max-x1_min)*(y1_max-y1_min)+(x2_max-x2_min)*(y2_max-y2_min)-intersect\n",
        "\n",
        "  return intersect/union\n",
        "\n",
        "'''def nonmax_suppression(filter_boxes,filter_labels,filter_scores):\n",
        "  \n",
        "  zipped_tuple = zip(filter_scores,filter_labels,filter_boxes)\n",
        "  zipped = [x for _,x in sorted(zipped_tuple)]\n",
        "\n",
        "  print(zipped)'''\n",
        "\n",
        "#nonmax_suppression(temp,filter_labels,filter_scores)\n",
        "zipped_tuple = zip(filter_scores,filter_labels,temp)\n",
        "temp1 = sorted(zipped_tuple,reverse=True)\n",
        "boxes_list = np.array([i[2] for i in temp1])\n",
        "pick = []\n",
        "idxs = np.arange(len(temp1))\n",
        "\n",
        "while len(idxs)>0:\n",
        "  pick_i = idxs[0]\n",
        "  pick.append(pick_i)\n",
        "  pick_box = boxes_list[pick_i]\n",
        "  \n",
        "\n",
        "  overlap = intersection_union(pick_box,boxes_list,idxs)\n",
        "\n",
        "  idxs = np.delete(idxs,np.concatenate(([0],np.where(overlap>0.2)[0])))\n",
        "\n",
        "#print('pick',pick)\n",
        "img2 = copy.deepcopy(img)\n",
        "#out = display(img2,display_id=True)\n",
        "counter=0\n",
        "for i in pick:\n",
        "  coords = temp1[i][2]\n",
        "  x1 = coords[0]\n",
        "  y1 = coords[1]\n",
        "  x2 = coords[2]\n",
        "  y2 = coords[3]\n",
        "  im = ImageDraw.Draw(img2)\n",
        "  im.rectangle([(x1,y1),(x2,y2)],outline='blue')\n",
        "  print([(x1,y1),(x2,y2)])\n",
        "  print(temp1[i][1])\n",
        "  print(temp1[i][0])\n",
        "  \n",
        "'''for i in temp:\n",
        "  coords = i\n",
        "  x1 = coords[0]\n",
        "  y1 = coords[1]\n",
        "  x2 = coords[2]\n",
        "  y2 = coords[3]\n",
        "  im = ImageDraw.Draw(img2)\n",
        "  im.rectangle([(x1,y1),(x2,y2)],outline='red')\n",
        "  print([(x1,y1),(x2,y2)])\n",
        "  #print(temp1[i][1])\n",
        "  #print(temp1[i][0])\n",
        "'''\n",
        "display(img2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uxr2SYK8Uxd"
      },
      "source": [
        "bndbox = []\n",
        "tree = et.parse('./VOCdevkit/VOC2007/Annotations/000005.xml')\n",
        "img2 = Image.open('./VOCdevkit/VOC2007/JPEGImages/000005.jpg')\n",
        "root = tree.getroot()\n",
        "for child in root:\n",
        "  if child.tag=='object':\n",
        "    name = ''\n",
        "    for child1 in child:\n",
        "      \n",
        "      if child1.tag=='name':\n",
        "        name = child1.text\n",
        "      elif child1.tag=='bndbox':\n",
        "        print(name)\n",
        "        #classes.add(name)\n",
        "        #print(child1[0].text,child1[1].text,child1[2].text,child1[3].text)\n",
        "        x_min = int(child1[0].text)\n",
        "        y_min = int(child1[1].text)\n",
        "        x_max = int(child1[2].text)\n",
        "        y_max = int(child1[3].text)\n",
        "        #cv2.rectangle(img,(x_min,y_min),(x_max,y_max),(255,0,0),2)\n",
        "        im = ImageDraw.Draw(img2)\n",
        "        im.rectangle([(x_min,y_min),(x_max,y_max)],outline='red')\n",
        "        print([(x_min,y_min),(x_max,y_max)])\n",
        "        bndbox.append([x_min,y_min,x_max,y_max])\n",
        "\n",
        "display(img2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5qkzrjH8U06"
      },
      "source": [
        "from PIL import ImageDraw\n",
        "\n",
        "img = Image.open('./VOCdevkit/VOC2007/JPEGImages/000009.jpg')\n",
        "\n",
        "w,h = img.size\n",
        "print(w,h)\n",
        "width  = [128,256,512,int(w/2),w]\n",
        "height = [128,256,512,int(h/2),h]\n",
        "\n",
        "boxes = []\n",
        "out = display(img,display_id=True)\n",
        "for s_w in width:\n",
        "  for s_h in height:\n",
        "    for y in range(0,h-s_h+1,16):\n",
        "      for x in range(0,w-s_w+1,16):\n",
        "        #img2 = copy.deepcopy(img)\n",
        "        #img1 = img.crop((x,y,x+s_w,y+s_h))\n",
        "        #img1 = data_transforms(img1)\n",
        "        #detections.append(img1)\n",
        "        boxes.append(torch.tensor([x,y,x+s_w,y+s_h]))\n",
        "        #im = ImageDraw.Draw(img2)\n",
        "        #im.rectangle([(x,y),(x+s_w,y+s_h)],outline='red')\n",
        "        #out.update(img2)\n",
        "        #time.sleep(0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuRhWOAh8P0X"
      },
      "source": [
        "boxes = {}\n",
        "for i in val_files:\n",
        "  \n",
        "  path = './VOCdevkit/VOC2007/JPEGImages/'+i[i.rfind('/')+1:].split('.')[0]+'.jpg'\n",
        "\n",
        "  boxes[path] = []\n",
        "  img = Image.open(path)\n",
        "\n",
        "  w,h = img.size\n",
        "  #print(w,h)\n",
        "  width  = [128,256,512,int(w/2),w]\n",
        "  height = [128,256,512,int(h/2),h]\n",
        "\n",
        "  \n",
        "  #out = display(img,display_id=True)\n",
        "  for s_w in width:\n",
        "    for s_h in height:\n",
        "      for y in range(0,h-s_h+1,16):\n",
        "        for x in range(0,w-s_w+1,16):\n",
        "          \n",
        "          boxes[path].append(torch.tensor([x,y,x+s_w,y+s_h]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7xp9sJ_8es2"
      },
      "source": [
        "detections = []\n",
        "model_ft.eval()\n",
        "counter=0\n",
        "\n",
        "for index in boxes:\n",
        "  check_boxes = torch.stack(boxes[index])\n",
        "\n",
        "  img = Image.open(index)\n",
        "\n",
        "    \n",
        "  filter_boxes = []\n",
        "  filter_labels = []\n",
        "  filter_scores = []\n",
        "\n",
        "  \n",
        "  dataset_temp = TensorDataset(check_boxes)\n",
        "  temp1 = DataLoader(dataset_temp,batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for boxes1 in temp1:\n",
        "      inputs = []\n",
        "      for i in boxes1[0]:\n",
        "        a = i[0].item()\n",
        "        b = i[1].item()\n",
        "        c = i[2].item()\n",
        "        d = i[3].item()\n",
        "\n",
        "        img1 = img.crop((a,b,c,d))\n",
        "        img1 = data_transforms(img1)\n",
        "        inputs.append(img1)\n",
        "      \n",
        "      inputs = torch.stack(inputs)\n",
        "      inputs = inputs.to(device)\n",
        "      \n",
        "\n",
        "      outputs = model_ft(inputs)\n",
        "      prob = nn.functional.softmax(outputs,dim=1)\n",
        "      \n",
        "\n",
        "    \n",
        "      prob,indices = torch.sort(prob,descending=True)\n",
        "      prob = prob[:,:1]\n",
        "      #print('prob',prob)\n",
        "\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      #print('_,preds ',_,preds)\n",
        "      #print('boxes1',boxes1)\n",
        "      \n",
        "      preds1 = preds.to(\"cpu\").numpy()\n",
        "      prob1 = prob.to(\"cpu\").numpy()\n",
        "\n",
        "      for i in range(len(preds1)):\n",
        "        \n",
        "        val = float(prob1[i])\n",
        "        #print('val',val)\n",
        "  \n",
        "        label = class_names[preds1[i]]\n",
        "        #print('label',label)\n",
        "        if label !='background':\n",
        "          #filter_detections.append(inputs[i])\n",
        "          \n",
        "          filter_boxes.append(list(boxes1[0][i].numpy()))\n",
        "          filter_labels.append(label)\n",
        "          filter_scores.append(val)\n",
        "\n",
        "  detections.append([index,filter_labels,filter_scores,filter_boxes])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7yAKnlG8exG"
      },
      "source": [
        "\n",
        "'''import pickle\n",
        "with open('detection_list.pkl','wb') as f:\n",
        "  pickle.dump(detections,f)\n",
        "\n",
        "detections[0]'''\n",
        "x = torch.randn(1,2)\n",
        "x = x.to(device)\n",
        "print(x)\n",
        "val = x[0][0]*x[0][1].item()\n",
        "x[0][0].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V1Y6xXC8e1T"
      },
      "source": [
        "!cp ./drive/MyDrive/object_detection/detection.zip ./\n",
        "!unzip detection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ay1M2K8P4Q"
      },
      "source": [
        "with open('detection_list.pkl','rb') as f:\n",
        "  detections = pickle.load(f)\n",
        "\n",
        "len(detections)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsoI75vG8l9Q"
      },
      "source": [
        "def intersection_union(b,b1,idxs):\n",
        "  max_val=0\n",
        "  x1_min = b[0]\n",
        "  y1_min = b[1]\n",
        "  x1_max = b[2]\n",
        "  y1_max = b[3]\n",
        "  \n",
        "  x2_min = b1[idxs[:],0]\n",
        "  y2_min = b1[idxs[:],1]\n",
        "  x2_max = b1[idxs[:],2]\n",
        "  y2_max = b1[idxs[:],3]\n",
        "\n",
        "  #print(x1_min,y1_min,x1_max,y1_max,x2_min,y2_min,x2_max,y2_max)\n",
        "  \n",
        "\n",
        "  x1 = np.minimum(x1_max,x2_max)\n",
        "  x2 = np.maximum(x1_min,x2_min)\n",
        "  y1 = np.minimum(y1_max,y2_max)\n",
        "  y2 = np.maximum(y1_min,y2_min)\n",
        "\n",
        "  #print(x1,x2,y1,y2)\n",
        "\n",
        "  x_dist = np.maximum(0,(x1 - x2))\n",
        "  y_dist = np.maximum(0,(y1-y2))\n",
        "\n",
        "  intersect = x_dist * y_dist\n",
        "  \n",
        "  union = (x1_max-x1_min)*(y1_max-y1_min)+(x2_max-x2_min)*(y2_max-y2_min)-intersect\n",
        "\n",
        "  return intersect/union\n",
        "\n",
        "filter_detections = []\n",
        "for i in detections:\n",
        "  \n",
        "  #nonmax_suppression(temp,filter_labels,filter_scores)\n",
        "  f = i[0]\n",
        "  zipped_tuple = zip(i[2],i[1],i[3])\n",
        "  temp1 = sorted(zipped_tuple,reverse=True)\n",
        "  boxes_list = np.array([j[2] for j in temp1])\n",
        "  pick = []\n",
        "  idxs = np.arange(len(temp1))\n",
        "\n",
        "  while len(idxs)>0:\n",
        "    pick_i = idxs[0]\n",
        "    pick.append(pick_i)\n",
        "    pick_box = boxes_list[pick_i]\n",
        "    \n",
        "\n",
        "    overlap = intersection_union(pick_box,boxes_list,idxs)\n",
        "\n",
        "    idxs = np.delete(idxs,np.concatenate(([0],np.where(overlap>0.4)[0])))\n",
        "\n",
        "  \n",
        "  #img2 = copy.deepcopy(img)\n",
        "  #out = display(img2,display_id=True)\n",
        "  #counter=0\n",
        "  filter_boxes = []\n",
        "  filter_labels = []\n",
        "  filter_scores = []\n",
        "  for k in pick:\n",
        "    '''coords = temp1[k][2]\n",
        "    x1 = coords[0]\n",
        "    y1 = coords[1]\n",
        "    x2 = coords[2]\n",
        "    y2 = coords[3]\n",
        "    im = ImageDraw.Draw(img2)\n",
        "    im.rectangle([(x1,y1),(x2,y2)],outline='blue')\n",
        "    print([(x1,y1),(x2,y2)])'''\n",
        "    filter_boxes.append(temp1[k][2])\n",
        "    filter_labels.append(temp1[k][1])\n",
        "    filter_scores.append(temp1[k][0])\n",
        "  \n",
        "  filter_detections.append([f,filter_labels,filter_scores,filter_boxes])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGBtUixn8mCL"
      },
      "source": [
        "filter_detections[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2mc8LgM8mFz"
      },
      "source": [
        "def intersection_union(b,b1):\n",
        "  max_val=0\n",
        "  x1_min = b[0]\n",
        "  y1_min = b[1]\n",
        "  x1_max = b[2]\n",
        "  y1_max = b[3]\n",
        "  \n",
        "  x2_min = b1[:,0]\n",
        "  y2_min = b1[:,1]\n",
        "  x2_max = b1[:,2]\n",
        "  y2_max = b1[:,3]\n",
        "\n",
        "  #print(x1_min,y1_min,x1_max,y1_max,x2_min,y2_min,x2_max,y2_max)\n",
        "  \n",
        "\n",
        "  x1 = np.minimum(x1_max,x2_max)\n",
        "  x2 = np.maximum(x1_min,x2_min)\n",
        "  y1 = np.minimum(y1_max,y2_max)\n",
        "  y2 = np.maximum(y1_min,y2_min)\n",
        "\n",
        "  #print(x1,x2,y1,y2)\n",
        "\n",
        "  x_dist = np.maximum(0,(x1 - x2))\n",
        "  y_dist = np.maximum(0,(y1-y2))\n",
        "\n",
        "  intersect = x_dist * y_dist\n",
        "  \n",
        "  union = (x1_max-x1_min)*(y1_max-y1_min)+(x2_max-x2_min)*(y2_max-y2_min)-intersect\n",
        "\n",
        "  return intersect/union\n",
        "\n",
        "def calc_mAP(predictions,dataset1,iou_thresh,num_classes):\n",
        "\n",
        "  average_precisions = []\n",
        "  for class_c in range(1,num_classes):\n",
        "    filter_predictions = []\n",
        "    filter_true_box = {}\n",
        "    total_ground_truth=0\n",
        "  \n",
        "    for i in predictions:\n",
        "      f = i[0]\n",
        "      pred_class = i[1]\n",
        "      #pred_boxes = i[3]\n",
        "    \n",
        "      for j,lab in enumerate(pred_class):\n",
        "        if labels_dict[lab]==class_c:          \n",
        "          filter_predictions.append([f,class_c,i[2][j],i[3][j]])\n",
        "        \n",
        "      true_class = dataset1.data1[f][1]\n",
        "      true_boxes = dataset1.data1[f][0]\n",
        "      filter_true_box[f] = []\n",
        "\n",
        "      for j in range(len(true_class)):\n",
        "        if true_class[j]==class_c:\n",
        "          filter_true_box[f].append(true_boxes[j])\n",
        "          total_ground_truth+=1\n",
        "      \n",
        "      \n",
        "    TP = torch.zeros(len(filter_predictions))\n",
        "    FP = torch.zeros(len(filter_predictions))\n",
        "    #taken = torch.zeros(len(filter_true_box))\n",
        "    taken = {}\n",
        "    for key in filter_true_box:\n",
        "      taken[key] = torch.zeros(len(filter_true_box[key]))\n",
        "    \n",
        "    \n",
        "\n",
        "    #print('filter_true_box ',filter_true_box,'\\ntotal ground truth ',total_ground_truth)\n",
        "    filter_predictions.sort(key=lambda x:x[2],reverse=True)\n",
        "    \n",
        "    for j,prediction in enumerate(filter_predictions):\n",
        "\n",
        "      f = prediction[0]\n",
        "      true_boxes = np.array(filter_true_box[f]) \n",
        "      #print('true_boxes ',type(true_boxes),true_boxes)\n",
        "      \n",
        "      if true_boxes.shape[0]==0:\n",
        "        FP[j]=1\n",
        "        continue\n",
        "\n",
        "      iou_overlap = intersection_union(prediction[3],true_boxes)\n",
        "\n",
        "      #print(iou_overlap)\n",
        "      max_iou = np.max(iou_overlap,0)\n",
        "      idx = np.argmax(iou_overlap)\n",
        "\n",
        "      if max_iou >= iou_thresh:\n",
        "        \n",
        "        if taken[f][idx]==0:\n",
        "          TP[j]=1\n",
        "          taken[f][idx]=1\n",
        "      \n",
        "        else:\n",
        "          FP[j] = 1\n",
        "\n",
        "      else:\n",
        "        FP[j] = 1\n",
        "      \n",
        "    TP_cumsum = torch.cumsum(TP,dim=0)\n",
        "    FP_cumsum = torch.cumsum(FP,dim=0)\n",
        "    recalls = TP_cumsum/total_ground_truth\n",
        "    precisions = TP_cumsum/(TP_cumsum+FP_cumsum)\n",
        "    precisions = torch.cat((torch.tensor([1]), precisions))\n",
        "    recalls = torch.cat((torch.tensor([0]), recalls))\n",
        "    average_precisions.append(torch.trapz(precisions,recalls))\n",
        "    #print(recalls,'\\n', precisions)\n",
        "    plt.plot(recalls,precisions)\n",
        "    #plt.xticks(np.arange(0,1.1,0.1))\n",
        "    #plt.yticks(np.arange(0,1.1,0.1))\n",
        "    plt.xlabel('recalls')\n",
        "    plt.ylabel('precisions')\n",
        "    plt.title(class_names[class_c])\n",
        "    plt.savefig('{}.png'.format(class_names[class_c]))\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "\n",
        "  print(sum(average_precisions)/len(average_precisions))\n",
        "\n",
        "\n",
        "calc_mAP(filter_detections,dataset1,0.3,21)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejq_HwgZ8vnn"
      },
      "source": [
        "!rm *.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aNpiUxx8vrG"
      },
      "source": [
        "Image.open('./VOCdevkit/VOC2007/JPEGImages/000005.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0iNSPzK8vv_"
      },
      "source": [
        "img = Image.open('./VOCdevkit/VOC2007/JPEGImages/006524.jpg')\n",
        "data_transforms = torchvision.transforms.Compose([torchvision.transforms.Resize((256)),\n",
        "                                                  transforms.RandomVerticalFlip(),\n",
        "                                                  transforms.RandomHorizontalFlip(),\n",
        "                                                  transforms.RandomAffine(degrees=0,translate=(0.25,0.25))])\n",
        "\n",
        "#temp = data_transforms(img)\n",
        "w,h = img.size\n",
        "diff=0\n",
        "diff1=0\n",
        "w1=0\n",
        "w2=0\n",
        "h1=0\n",
        "h2=0\n",
        "a=0\n",
        "b=0\n",
        "while diff<64:\n",
        "  a = np.random.random()\n",
        "  a1 = int(a*w)\n",
        "  b = np.random.random()\n",
        "  b1 = int(b*w)\n",
        "  w1 = np.minimum(a1,b1)\n",
        "  w2 = np.maximum(a1,b1)\n",
        "  diff = w2-w1\n",
        "#print(w1,w2,a,b)\n",
        "while diff1<64:\n",
        "  a = np.random.random()\n",
        "  a1 = int(a*h)\n",
        "  b = np.random.random()\n",
        "  b1 = int(b*h)\n",
        "  h1 = np.minimum(a1,b1)\n",
        "  h2 = np.maximum(a1,b1)\n",
        "  diff1 = h2-h1\n",
        "#print(h1,h2,a,b)\n",
        "img.crop((w1,h1,w2,h2))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}